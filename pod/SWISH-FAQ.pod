=head1 NAME

The SWISH-E FAQ - Answers to Common Questions

=head1 Frequently Asked Questions

=head2 What is SWISH-E?

SWISH-E is B<S>imple B<W>eb B<I>ndexing B<S>ystem for B<H>umans - B<E>nhanced.
With it, you can quickly and easily index directories of files or remote web sites and search the generated
indexes for words and phrases.

=head2 So, is SWISH-E a search engine?

Well, yes.  Probably the most common use of swish-e is to provide a search engine for web sites.
The swish-e distribution includes CGI scripts that can be used with swish-e
to add a I<search engine> for your web site.  The CGI scripts can be found in the F<example>
directory of the distribution package.  See the F<README> file for information about the scripts.

But swish-e can also be used to index all sorts of data, such as email messages, data stored in a
relational database management system, XML documents, or documents such as Word and PDF documents -- or any combination
of those sources.  Searches can be limited to fields or I<MetaNames> within a document, or limited to areas within
an HTML document (e.g. body, title).  Programs other than CGI applications can use swish, as well.

=head2 Should I upgrade if I'm already running a previous version of swish?

A large number of bug fixes, feature additions, and logic corrections were made in version 2.2.
In addition, indexing speed has been drastically improved (reports of indexing times changing from four hours
to twenty minutes), and major parts of the indexing and search parsers have been rewritten.  There's better debugging
options, enhanced output formats, more document meta data (e.g. last modified date, document summary),
options for indexing from external data sources, and faster spidering just to name a few changes.  (See the CHANGES
file for more information.

Since so much effort has gone into version 2.2, support for previous versions will probably be limited.

=head2 Are there binary distributions available for Swish-e on platform foo?

Foo?  Well, yes there are some binary distributions available.  Please see the swish-e web site for
a list at http://sunsite.berkeley.edu/SWISH-E/.

In general, it is recommended that you build swish from source, if possible.

=head2 I've tried running the included CGI script and I get a "Internal Server Error"

Debugging CGI scripts are beyond the scope of this document.  Internal Server Error basically means
"check the web server's log for an error message", as it can mean anything from a bad shebang (#!)
line to an error in the program.  The CGI script F<swish.cgi> in the F<example> directory contains some
debugging suggestions.  Type C<perldoc swish.cgi> for information.

There are also many, many CGI FAQs available on the Internet.  A quick web search should offer help.  As
a last resort you might ask your webadmin for help...

=head2 When I try to view the swish.cgi page I see the contents of the Perl program.

Your web server is not configured to run the program as a CGI script.  This problem is described in
C<perldoc swish.cgi>.


=head2 I have read the FAQ but I still have questions about using Swish-e.

The SWISH-E discussion list is the place to go.  http://sunsite.berkeley.edu/SWISH-E/.  Please do not
email developers directly.  The list is the best place to ask questions.

Before you post please read I<QUESTIONS AND TROUBLESHOOTING> located in the L<INSTALL|INSTALL> page.

In short, be sure to include in the following when asking for help.

=over 4

=item * The swish-e version (./swish-e -V)

=item * What you are indexing (and perhaps a sample), and the number of files

=item * Your swish-e configuration file

=item * Any error messages that swish-e is reporting

=back


=head2 Swish isn't indexing a certain word or phrase. 

By default, swish-e tries to make it best guesses as to what it thinks are reasonable words and filters out "garbage" words according to a set
of rules, for instance, if swish-e encounters a word that has no vowels, it doesn't index it. You can change these rules by editing the config.h
file in the src directory of the swish-e distribution package. By editing the rules, you may be able to index quite a few more words, or less,
depending on your preference.

Configuration file directives (L<SWISH-CONFIG|SWISH-CONFIG>)
C<WordCharacters>, C<BeginCharacters>, C<EndCharacters>,
C<IgnoreFirstChar>, and C<IgnoreLastChar> also control what words swish indexes.

Use of the command line arguments C<-k>, C<-v> and C<-T> are useful when debugging these issues.
Using C<-T INDEXED_WORDS> while indexing will display each word as it is indexed.  You should specify one file
when using this feature since it can generate a lot of output.

     ./swish-e -c my.conf -i problem.file -T INDEXED_WORDS
     
You may also wish to index a single file that contains words that are or are not indexing as you expect
and use -T to out debugging information about the index.  A useful command might be:

    ./swish-e -f index.swish-e -T INDEX_FULL

=head2 Swish crashes and burns on a certain file. What can I do?

This shouldn't happen.  If it does please post to the swish-e discussion list the details so it can be
reproduced by the developers.

In the mean time, you can use a FileRules operation to exclude the particular file name, or pathname, or its title.
If there are serious problems in indexing certain types of files, they may not have valid text
in them (they may be binary files, for instance). You can use NoContents to exclude that
type of file.

Swish will issue a warning if an embedded null character is found in a document.  The document will be truncated
at the null.  This warning will be an indication
that you are trying to index binary data.  If you need to index binary files try to find a program that will
extract out the text (e.g. strings(1), catdoc(1), pdftotext(1)).

=head2 Can I reindex and search at the same time?

It's probably best to specify a temporary IndexFile file in your configuration and then rename the index
to the live index name after indexing is complete.  Under unix rename (mv) is atomic, so any searches in progress not
be effected.

=head2 How can I index documents on a web server?

If possible, use the file system method C<-S fs> of indexing to index documents in you web area of the file
system.  This avoids the overhead of spidering a web server and is much faster.
(C<-S fs> is the default method if C<-S> is not specified).

If this is impossible (the web server is not local, or documents are dynamically generated), swish provides
two methods of spidering.  First, swish includes the http method of indexing C<-S http>. A number of
special configuration directives are available that control spidering
(see L<Directives for the HTTP Access Method Only|/"Directives for the HTTP Access Method Only">).
A perl helper script (swishspider.pl) is included in the F<src> directory to assist with spidering
web servers.  There are example configurations for spidering in the F<conf> directory.

As of swish 2.2, there's a general purpose "prog" document source where a program can feed documents to
swish for indexing.  A number of example programs can be found in the C<prog-bin> directory, including
a program to spider web servers.  The provided spider.pl program is full-featured and is easily customized.

The advantage of the "prog" document source feature over the "http" method is that the program is only executed
one time, where the swishspider.pl program used in the "http" method is executed once for every document
read from the web server.  The forking of swish and compiling of the perl script can be quite expensive, time-wise.

The other advantage of the C<spider.pl> program is that it's simple and efficient to add filtering (such as for PDF or MS Word docs)
right into the spider.pl's configuration, and it includes features such as MD5 checks to prevent duplicate indexing,
options to avoid spidering some files, or index but avoid spidering.  And since it's a perl program there's no limit
on the features you can add.

=head2 Swish is not indexing Javascript links!

Swish cannot follow links generated by Javascript, as they are generated by the browser and are not part of
the document.

=head2 How to I prevent indexing of some web pages?

Use a F<robots.text> file in your document root.  This is a standard way to excluded files from search engines, and
is fully supported by swish-e.  See http://www.robotstxt.org/

You can also modify the F<spider.pl> spider perl program to skip, index content only, or spider only listed web
pages.

=head2 I'm using the C<spider.pl> program to spider my web site, but some files large files are not indexed.

The C<spider.pl> program has a default limit of 5MB file size.  This can be changed with the C<max_size>
parameter setting.  See C<perldoc spider.pl> for more information.

=head2 I still don't think all my web pages are being indexed.

The F<spider.pl> program has a number of debugging switches and can be quite verbose in telling you
what's happening, and why.  See C<perldoc spider.pl> for instructions.


=head2 How do I modify the path or URL of the indexed documents.

Use the C<ReplaceRules> configuration directive to rewrite path names and URLs.

=head2 How can I index data from a database?

Use the "prog" document source method of indexing.  Write a program to extract out the data from your
database, and format it as XML, HTML, or text.  See the examples in the C<prog-bin> directory, and the next
question.

=head2 Can I index my PDF, Word, and compressed documents?

Swish-e can internally only handle HTML, WML, XML and TXT (text) files by default, but
can make use of I<filters> that will convert other types of files such as MS Word documents, PDF,
or gzipped files into one of the file types that Swish-e understands.

The B<FileFilter> config directive is used to define programs to use as filters, based
on file extension.  For example, you can use the program C<catdoc> to convert MS-Word documents to text for indexing.
Please see L<SWISH-CONFIG|SWISH-CONFIG/"Document Filter Directives"> and the examples in the C<filter-bin>
directory for more information.

Another option is to use the C<prog> document source input method.
In this case you write a program (such as a perl script) that will read and convert your data as needed
and then output one of the formats that swish understands.  Examples of using the C<prog> input method for
filtering are included in the C<prog-bin> directory of the Swish-e distribution.

The disadvantage of using the C<prog> input method is that you must write a program that reads the documents
from the source (e.g. from the file system or via a spider to read files on a web server), and also include
the code to filter the documents.
It's much easier to use the C<FileFilter> option since the filter can often be implemented with just a single
configuration directive.

On the other hand, the advantage of using the C<prog> input method for indexing is speed.  Filtering
within a C<prog> input method program will be faster if your filtering program is something
like a Perl script (something that has a large start-up cost).  This may or may not be
an issue for you, depending on how much time your indexing requires.

You can also use a combination of methods.  For example, say you are indexing a directory that contains PDF
files using a C<FileFilter> directive.  Now you want to index a MySQL database that also contains PDF files.
You can write a C<prog> input method program to read your MySQL database and use the same C<FileFilter> configuration
parameter (and filter program) to convert the PDF files into one of the native swish formats (TXT, HTML, XML).

Do note that it will be slower to use the C<FileFilter> method instead of running the filter directly from the
C<prog> input method program.  When C<FileFilter> is used with the C<prog> input method swish must create a temporary file
containing the output from your C<prog> method program, and then execute the filter program.

In general, use the C<FileFilter> method to filter documents.  If indexing speed is an issue, consider writing a
C<prog> input method program.  If you are already using the C<prog> method, then filtering will probably be best
accomplished within that program.

Here's two examples of how to run a filter program, one using swish's C<FileFilter> directive, another using
a C<prog> input method program.
These filters simply use the program C</bin/cat> as a filter and only indexes .html files.

First, using the C<FileFilter> method, here's the entire configuration file (swish.conf):

    IndexDir .
    IndexOnly .html
    FileFilter .html "/bin/cat"   "'%p'"

and index with the command

    swish-e -c swish.conf -v 1

Now, the same thing with using the C<prog> document source input method and a Perl program called
catfilter.pl.  You can see that's it's much more work than using the C<FileFilter> method above,
but provides a place to do additional processing.  In this example, the C<prog> method is only slightly faster.
But if you needed a perl script to run as a FileFilter then C<prog> will be significantly faster.

    #!/usr/local/bin/perl -w
    use strict;
    use File::Find;  # for recursing a directory tree

    $/ = undef;
    find(
        { wanted => \&wanted, no_chdir => 1, },
        '.',
    );

    sub wanted {
        return if -d;
        return unless /\.html$/;

        my $mtime  = (stat)[9];

        my $child = open( FH, '-|' );
        die "Failed to fork $!" unless defined $child;
        exec '/bin/cat', $_ unless $child;

        my $content = <FH>;
        my $size = length $content;

        print <<EOF;
    Content-Length: $size
    Last-Mtime: $mtime
    Path-Name: $_

    EOF

        print <FH>;
    }

And index with the command:

    swish-e -S prog -i ./catfilter.pl -v 1

This example will probably not work under Windows due to the '-|' open.  A simple piped
open may work just as well:

That is, replace:

    my $child = open( FH, '-|' );
    die "Failed to fork $!" unless defined $child;
    exec '/bin/cat', $_ unless $child;

with this:

    open( FH, "/bin/cat $_ |" ) or die $!;

Perl will try to avoid running the command through the shell if meta characters are not passed
to the open.  See C<perldoc -f open> for more information.

=head2 Eh, but I just want to know how to index PDF documents!

See the examples in the F<conf> directory.

=head2 I'm using the C<prog> method to index PDF documents, but the file contents are not indexed.

The examples in the F<prog-bin> directory use a module to convert the PDF files into XML.  So you must
tell swish that you are indexing XML files for the PDF extension.

    IndexContents XML .pdf

=head2 Do filters effect the performance during search?

No. Filters (FileFilter or via "prog" method) are only used for building the search index 
database.  During search requests there will be no filter calls.


=head2 Can I index 8-bit text? 

Yes, you can. Just remember that swish-e retains capitalization for all characters other than [a-z A-Z], so the word "Çelik" is not retrieved by
"çelik", "Celik", or "celik". You can index and use words containing any entity from ! (#033) to ÿ (#255).

(note: but swish uses tolower(3), so locale settings may apply.)

Also, the TranslateCharacters directive (L<SWISH-CONFIG|SWISH-CONFIG>) can translate characters while indexing
and searching.  C<TranslateCharacters :ascii7:> is a predefined set of characters that will translate eight bit characters to ascii7 characters.
Using the :ascii7: rule will translate "Ääç" to "aac". This means: searching "Çelik", "çelik" or "celik"
will all match the same word.  


=head2 How can I index phrases? 

Phrases are indexed automatically.  To search for a phrase simply place double quotes around the phrase.

For example:

    swish-e -w 'free and "fast search engine"'

=head2 How can I prevent phrases from matching across sentences?

Use the L<BumpPositionCounterCharacters|/"item_BumpPositionCounterCharacters"> configuration
directive.


=head2 How can I implement keywords in my documents? 

In your HTML files you can put keywords in HTML META tags or in XML blocks.

META tags can have three formats in your source documents:

    <META NAME="DC.subject" CONTENT="digital libraries">

    <!-- META START NAME="meta1" -->
        some content
    <!-- META END -->

And in XML format

    <meta2>
        Some Content
    </meta2>


Then, to inform SWISH-E about the existence of the meta name in your documents,
edit the line in your configuration file:

    MetaNames DC.subject meta1 meta2

=head2 What are I<document properties>?

A document property is typically data that describes the document.  For example,
properties might include a document's path name, its last modified date,
its title, or its size.
Swish stores a document's properties in the index file,
and they can be reported back in search results.

Swish also uses properties for sorting.  You may sort your results by
one or more properties, in ascending or descending order.

Properties can also be defined within your documents.  HTML and XML files
can specifify tags (see previous question) as properties.  The I<contents>
of these tags can then be returned with search results.
These user-defined properties can also be used for sorting search results.

For example, if you had the following in your documents

   <meta name="creator" content="accounting department">

And C<creator> is defined as a property
(see C<PropertyNames> in L<SWISH-CONFIG|SWISH-CONFIG>)
swish can return C<accounting department> with the result for that
document.

    swish-e -w foo -p creator

Or for sorting:

    swish-e -w foo -s creator

=head2 What's the difference between I<MetaNames> and I<PropertyNames>?

MetaNames allows keywords searches in your documents.
That is, you can use MetaNames to restrict searches to just parts of
your documents.

PropertyNames, on the other hand, define text that
can be returned with results, and can be used for sorting.

Both use I<meta tags> found in your documents
(as shown in the above two questions) to define
the text you wish to use as a property or meta name.

You may define a tag as B<both> a property and a meta name.  For example:

   <meta name="creator" content="accounting department">

placed in your documents and then using configuration settings of:

    PropertyNames creator
    MetaNames creator

will allow you to limit your searches to documents created by accounting:

    swish-e -w 'foo and creator=(accounting)'

That will find all documents with the word C<foo> that also have a creator meta tag
that contains the word C<accounting>.  This is using MetaNames.

And you can also say:

    swish-e -w foo -p creator

which will return all documents with the word C<foo>, but the results will
also include the contents of the C<creator> meta tag along with results.
This is using properties.

You can use properties and meta names at the same time, too:

    swish-e -w creator=(accounting or marketing) -p creator -s creator

That searches only in the C<creator> I<meta name> for either of the words
C<accounting> or C<marketing>, prints out the contents of the contents
of the C<creator> I<property>, and sorts the results by the C<creator>
I<property name>.

(See also the C<-x> output format switch in L<SWISH-RUN|SWISH-RUN>.)

=head2 I run out of memory trying to index my files. 

It's true that indexing can take up a lot of memory!
One thing you can do is make many indices of smaller content instead of trying to do
everything at once. You can then merge all the smaller pieces together with the C<-M> switch, or use
the C<-f> switch to specify more than one index while searching.

Another option is use the C<-e> switch.  This will require less memory, but indexing will take longer as
not all data will be stored in memory while indexing.  Please report back your findings as it seems C<-e>
requires quite a bit less RAM, but often not that much more indexing time.

=head2 I can't limit searches to title/body/comment.

Or, I<I can't search with meta names, all the names are indexed as "plain".>

Check in the config.h file if #define INDEXTAGS is set to 1. If it is, change it to 0, recompile, and index again. When INDEXTAGS is 1,
ALL the tags are indexed as plain text, that is you index "title", "h1", and so on, AND they loose their indexing meaning. If INDEXTAGS is
set to 0, you will still index meta tags and comments, unless you have indicated otherwise in the user config file with the IndexComments
directive.

Also, check for the C<UndefinedMetaTags> setting in your configuration file.

=head2 Do I need to reindex my site each time I upgrade to a new Swish-e version? 

At times it might not strictly be necessary, but since you don't really know if anything in the index has changed,
it is a good rule to reindex anyway. 

=head2 Does swish include a CGI interface?

An example CGI script is included in the C<example> directory.
(Type C<perldoc swish.cgi> in the C<example> directory for instructions.)

Please be careful when picking a CGI script to use with swish.  Quite a few of the scripts
that have been available for swish are insecure and should not be used.

The included example CGI script was designed with security in mind.  Regardless, you are encouraged
to have your local Perl expert review it (and all other CGI scripts you use) before placing into production.
This is just a good policy to follow.

=head2 How secure is swish?

We know of no security issues with using swish.  Careful attention has been made with regard to
common security problems such as buffer overruns when programming swish.

The most likely security issue with swish is when swish is run via a poorly written CGI interface.
This is not limited to CGI scripts written in Perl, as it's just as easy to write an insecure CGI script in
C, Java, PHP, or Python.  A good source of information is included with the Perl distribution.  Type
C<perldoc perlsec> at your local prompt for more information.  Another must-read document is located at
C<http://www.w3.org/Security/faq/wwwsf4.html>.

Note that there are many I<free> yet insecure and poorly written CGI scripts available --
even some designed for use with swish.
Free is not such a good price when you get your server hacked...

=head2 How do I make swish highlight words in search results?

Swish-e can't because it doesn't have access to the source documents when returning results,
of course.  But a front-end program of your creation can highlight terms.  Your program can open up the
source documents and then use regular expressions to replace search terms with highlighted or bolded
words.

But, that will fail with all but the most simple source documents.  For HTML documents, for example,
you must parse the document into words and tags (and comments).  A word you wish to highlight may span
multiple HTML tags, or be a word in a URL and you wish to highlight the entire link text.

Perl modules such as HTML::Parser
and XML::Parser make word extraction possible.  Next, you need to consider that swish uses settings such as
WordCharacters, BeginCharacters, EndCharacters, IgnoreFirstChar, and IgnoreLast, char to define a
"word".  That is, you can't consider that a string of characters with white space on each side is a word.

Then things like TranslateCharacters, and HTML Entities may transform a source word into something else,
as far as swish is concerned.  Finally, searches can be limited by metanames, so you may need to
limit your highlighting to only parts of the source document.
Throw phrase searches and stopwords into the equation
and you can see that it's not a trivial problem to solve.

All hope is not lost, thought, as swish does provide some help.
Using the C<-H> option swish will return in the headers the current index (or indexes) settings
for WordCharacters (and others) required to parse your source documents as swish parses them during indexing,
and will return a "Parsed Words:" header that will show how swish parsed the query internally.
If you use word stemming then you will also need to stem each word in your document before comparing
with the "Parsed Words:" returned by swish.  The swish-e stemming code is available either by using
the swish-e Perl module or C library (included with the swish-e distribution), or by using the SWISH::Stemmer
module available on CPAN.

=head2 My system admin says swish uses too much of the CPU!

That's a good thing!  That expensive CPU is suppose to be busy.

Indexing takes a lot of work -- to make indexing fast much of the work is done in memory, and
moving all that memory around requires CPU time.  But, there's two things you can try:

The C<-e> option will run swish in economy mode, which uses the disk to store data while indexing.
This makes swish run somewhat slower, but also uses less memory.  Since swish is writing to disk more often
it will be spending more time waiting on I/O and less time in CPU.  Maybe.

The other thing is to simply lower the priority of the job using the nice(1) command:

    /bin/nice -15 swish-e -c search.conf

If concerned about searching time, make sure you are using the -b and -m switches to only return
a page at a time.  If you know that your result sets will be large, and that you wish to return results
one page at a time, and that often times many pages of the same query will be requested, you may be smart
to request all the documents on the first request, and then cache the results to a temporary file.  The
perl module File::Cache makes this very simple to accomplish.

=head2 How do I pass swish a list of files to index?

Currently, there is not a configuration directive to include a file that contains a list of files to index.
But, there is a directive to include another configuration file.

    IncludeConfigFile /path/to/other/config

And in C</path/to/other/config> you can say:

    IndexDir file1 file2 file3 file4 file5 ...
    IndexDir file20 file21 file22

You may also specify more than one configuration file on the command line:

    ./swish-e -c config_one config_two config_three

Another option is to create a directory with symbolic links of the files to index,
and index just that directory.


=head2 How do I use Swish-E on a Windows Server?

Install Linux?

=head2 Can I add/remove files from an index?

Not really.  Swish currently has no way to add or remove items from its index.

About the only way to delete items from the index is to stat(2) all the results to make sure that
all the files still exist.

Incremental additions can be handled in a couple of ways, depending on your situation.  It's probably
easiest to create one main index every night (or every week), and then create an index of just the new files
between main indexing jobs and use the C<-f> option to pass both indexes to swish while searching.

You can merge the indexes into one index (instead of using -f),
but it's not clear that this has any advantage over searching multiple indexes.  Using C<-f> gives
access to the individual headers of both indexes, while C<-M> merges the headers, and merging indexes with
different indexing settings (Stemming, WordCharacters) may produce odd results.
This is a question for the swish-e discussion list.

How does one create the incremental index?

One method is by using the C<-N> switch to pass a file path to swish when indexing.
Swish will only index files that have a last modification date C<newer> than the file
supplied with the C<-N> switch.

This option has the disadvantage that swish must process every file in every directory
as if they were going to be indexed (the test for -N is done last right before indexing
of the file contents begin and after all other tests on the file have been completed)
-- all that just to find a few new files.
Also, if you use the swish index file as the file passed to -N there may be files
that were added after indexing was started, but before the index file was written.
This could result in a file not being added to the index.

Another option is to maintain a parallel directory tree that contains
symlinks pointing to the main files.
When a new file is added you create a symlink to the real file in the parallel
directory tree.
Then just index the symlink directory to generate the incremental index.

This option has the disadvantage that you need to have a central program that creates
the new files that can also create the symlinks.  But, indexing is quite fast since swish
only has to look at the files that need to be indexed.
When you run full indexing you simply unlink (delete) all the symlinks.

Both of these methods have issues where files could end up in both indexes, or files being left out of an index.
Use of file locks while indexing, and hash lookups during searches can help prevent these problems.

=head2 How do I spider other websites and combine it with my own (filesystem) index?

You can either merge C<-M> two indexes into a single index,
or use C<-f> to specify more than one index while searching.


=head1 Document Info

$Id$

.


